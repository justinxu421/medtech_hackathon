{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from wrapper import XRAY\n",
    "from split import split_data\n",
    "\n",
    "image_folder = 'images'\n",
    "label_path = 'Data_Entry_2017.csv'\n",
    "stats_filepath = 'outputs.txt'\n",
    "n_classes = 1 # regression problem\n",
    "use_parallel = True\n",
    "vision_model = torchvision.models.inception_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_weights = torch.tensor([1.,1.,5.])\n",
    "if torch.cuda.is_available():\n",
    "    loss_weights = loss_weights.cuda()\n",
    "# squared error loss\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_type = torch.optim.Adam\n",
    "lr_scheduler_type = optim.lr_scheduler.StepLR\n",
    "num_epochs = 2\n",
    "best_model_filepath = None\n",
    "load_model_filepath = None\n",
    "#load_model_filepath = 'model_best.pth.tar'\n",
    "\n",
    "def train_model(model, dataloaders, datasets, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    lowest_loss = 1000\n",
    "    \n",
    "    # list of models from all epochs\n",
    "    model_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                    model = model.cuda()\n",
    "                else:\n",
    "                    input = Variable(inputs)\n",
    "                    labels = Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                loss = criterion(outputs, labels.reshape(-1,1).float())\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss))\n",
    "            with open(stats_filepath, 'a') as f:\n",
    "                f.write('Epoch {} {} Loss: {:.4f} Acc: {:.4f}\\n'.format(epoch, phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':               \n",
    "                    \n",
    "                # update best model based on f1_score\n",
    "                if epoch_loss < lowest_loss:\n",
    "                    lowest_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "\n",
    "                    state = {'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "                    if best_model_filepath is not None:\n",
    "                        torch.save(state, best_model_filepath)\n",
    "        \n",
    "        model_list.append(copy.deepcopy(model))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(lowest_loss))\n",
    "    with open(stats_filepath, 'a') as f:\n",
    "        f.write('Best val loss: {:4f}\\n'.format(lowest_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model_list, model\n",
    "\n",
    "\n",
    "def evaluate_model(model, testset_loader, test_size, use_gpu):\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "    loss = 0\n",
    "    scores = []\n",
    "    # Iterate over data\n",
    "    for inputs, labels in tqdm(testset_loader):\n",
    "        # TODO: wrap them in Variable?\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        scores.extend(outputs.tolist())\n",
    "        loss += criterion(outputs, labels)\n",
    "    return (loss, scores)\n",
    "\n",
    "\n",
    "def load_saved_model(filepath, model, optimizer=None):\n",
    "    state = torch.load(filepath)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    # Only need to load optimizer if you are going to resume training on the model\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00000001_000.png', 2.0), ('00000001_001.png', 1.0), ('00000001_002.png', 2.0), ('00000002_000.png', 0.0), ('00000003_000.png', 0.0)]\n",
      "num experiments is 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin Xu\\Anaconda3\\envs\\cs231\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train filenames size:  3499\n",
      "validation filenames size:  750\n",
      "test filenames size:  750\n",
      "torch.Size([3, 299, 299])\n",
      "training dataset size:  3499\n",
      "validation dataset size:  750\n",
      "test dataset size:  750\n",
      "cpu\n",
      "[Using all the available GPUs]\n"
     ]
    }
   ],
   "source": [
    "train_filenames, val_filenames, test_filenames = split_data(label_path)\n",
    "print('train filenames size: ', len(train_filenames))\n",
    "print('validation filenames size: ', len(val_filenames))\n",
    "print('test filenames size: ', len(test_filenames))\n",
    "\n",
    "train_dataset = XRAY(image_folder, train_filenames)\n",
    "val_dataset = XRAY(image_folder, val_filenames)\n",
    "test_dataset = XRAY(image_folder, test_filenames)\n",
    "# print([y for img, y in train_dataset])\n",
    "# print([y for img, y in val_dataset])\n",
    "# print([y for img, y in test_dataset])\n",
    "\n",
    "#print out a sample image shape\n",
    "image_array, label = train_dataset[4]\n",
    "print(image_array.shape)\n",
    "print('training dataset size: ', len(train_dataset))\n",
    "print('validation dataset size: ', len(val_dataset))\n",
    "print('test dataset size: ', len(test_dataset))\n",
    "\n",
    "trainset_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=8)\n",
    "valset_loader = DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=8)\n",
    "testset_loader = DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=8)\n",
    "\n",
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Since imagenet has 1000 classes, we need to change our last layer to 1 so that we get a regression problem\n",
    "n_features = vision_model.fc.in_features\n",
    "vision_model.fc = nn.Linear(n_features, n_classes)\n",
    "\n",
    "# To view which layers are freezed and which layers are not freezed:\n",
    "# for name, child in vision_model.named_children():\n",
    "#     for name_2, params in child.named_parameters():\n",
    "#         print(name_2, params.requires_grad)\n",
    "\n",
    "if use_parallel:\n",
    "    print(\"[Using all the available GPUs]\")\n",
    "    vision_model = nn.DataParallel(vision_model, device_ids=[0, 1])\n",
    "\n",
    "dataloaders = {'train': trainset_loader, 'val': valset_loader}\n",
    "datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "optimizable_params = [param for param in vision_model.parameters() if param.requires_grad]\n",
    "optimizer = optimizer_type(optimizable_params, lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler_type(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# If we want to load a model with saved parameters\n",
    "if load_model_filepath is not None:\n",
    "    load_saved_model(load_model_filepath, vision_model, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/175 [00:00<?, ?it/s]C:\\Users\\Justin Xu\\Anaconda3\\envs\\cs231\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "\n",
      "  1%|▍                                                                               | 1/175 [01:06<3:14:16, 66.99s/it]\n",
      "  1%|▉                                                                               | 2/175 [01:44<2:30:46, 52.29s/it]\n",
      "  2%|█▎                                                                              | 3/175 [02:22<2:15:47, 47.37s/it]\n",
      "  2%|█▊                                                                              | 4/175 [02:56<2:05:25, 44.01s/it]\n",
      "  3%|██▎                                                                             | 5/175 [03:29<1:58:44, 41.91s/it]\n",
      "  3%|██▋                                                                             | 6/175 [04:07<1:56:14, 41.27s/it]\n",
      "  4%|███▏                                                                            | 7/175 [04:37<1:51:01, 39.65s/it]\n",
      "  5%|███▋                                                                            | 8/175 [05:04<1:45:46, 38.00s/it]\n",
      "  5%|████                                                                            | 9/175 [05:30<1:41:40, 36.75s/it]\n",
      "  6%|████▌                                                                          | 10/175 [06:00<1:39:09, 36.06s/it]\n",
      "  6%|████▉                                                                          | 11/175 [06:36<1:38:25, 36.01s/it]\n",
      "  7%|█████▍                                                                         | 12/175 [07:12<1:37:48, 36.00s/it]\n",
      "  7%|█████▊                                                                         | 13/175 [07:47<1:37:10, 35.99s/it]\n",
      "  8%|██████▎                                                                        | 14/175 [08:22<1:36:19, 35.90s/it]\n",
      "  9%|██████▊                                                                        | 15/175 [08:57<1:35:28, 35.80s/it]\n",
      "  9%|███████▏                                                                       | 16/175 [09:30<1:34:30, 35.66s/it]\n",
      " 10%|███████▋                                                                       | 17/175 [10:01<1:33:06, 35.36s/it]\n",
      " 10%|████████▏                                                                      | 18/175 [10:28<1:31:21, 34.92s/it]\n",
      " 11%|████████▌                                                                      | 19/175 [10:56<1:29:51, 34.56s/it]\n",
      " 11%|█████████                                                                      | 20/175 [11:22<1:28:13, 34.15s/it]\n",
      " 12%|█████████▍                                                                     | 21/175 [11:50<1:26:50, 33.83s/it]\n",
      " 13%|█████████▉                                                                     | 22/175 [12:15<1:25:17, 33.45s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5289767f4c91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                              \u001b[0mexp_lr_scheduler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                              \u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                              num_epochs)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-59511334379b>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, datasets, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;31m# backward + optimize only if in training phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs231\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list, best_model = train_model(vision_model,\n",
    "                             dataloaders,\n",
    "                             datasets,\n",
    "                             dataset_sizes,\n",
    "                             criterion,\n",
    "                             optimizer,\n",
    "                             exp_lr_scheduler,\n",
    "                             use_cuda,\n",
    "                             num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, scores = evaluate_model(best_model, testset_loader, len(test_dataset), use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
